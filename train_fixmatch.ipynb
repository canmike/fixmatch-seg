{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "device = \"cuda:0\"\n",
    "\n",
    "device = torch.device(device if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class SupervisedDataset(Dataset):\n",
    "    def __init__(self, image_folder, mask_folder, transform=None):\n",
    "        self.image_folder = image_folder\n",
    "        self.mask_folder = mask_folder\n",
    "        self.transform = transform\n",
    "        self.image_paths = os.listdir(image_folder)\n",
    "        self.mask_paths = os.listdir(mask_folder)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img_path = os.path.join(self.image_folder, self.image_paths[idx])\n",
    "        mask_path = os.path.join(self.mask_folder, self.mask_paths[idx])\n",
    "        \n",
    "        img = Image.open(img_path)\n",
    "        mask = Image.open(mask_path)\n",
    "\n",
    "        img = np.array(img)\n",
    "        mask = np.array(mask)\n",
    "\n",
    "        mask[mask == 128] = 1\n",
    "        mask[mask == 255] = 2\n",
    "\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=img, mask=mask)\n",
    "            img = transformed['image']\n",
    "            mask = transformed['mask']\n",
    "        \n",
    "        # Convert to torch tensor\n",
    "        img = torch.from_numpy(img).permute(2, 0, 1).float()\n",
    "        mask = torch.from_numpy(mask).long()\n",
    "\n",
    "        return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnsupervisedDataset(Dataset):\n",
    "    def __init__(self, image_folder, transform=None):\n",
    "        self.image_folder = image_folder\n",
    "        self.transform = transform\n",
    "        self.image_paths = os.listdir(image_folder)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_folder, self.image_paths[idx])\n",
    "        \n",
    "        img = Image.open(img_path)\n",
    "        img = np.array(img)\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "\n",
    "        # convert to torch tensor\n",
    "        img = torch.from_numpy(img).permute(2, 0, 1)\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "\n",
    "SIZE = 320\n",
    "labeled_transform = A.Compose([\n",
    "    A.Resize(320, 320),\n",
    "    ])\n",
    "\n",
    "unlabeled_transform = A.Compose([\n",
    "    A.Resize(320, 320),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_image_path = r'REFUGE2\\train\\images'\n",
    "labeled_mask_path = r'REFUGE2\\train\\mask'\n",
    "\n",
    "labeled_train_dataset = SupervisedDataset(labeled_image_path, labeled_mask_path, \n",
    "                            transform=labeled_transform)\n",
    "\n",
    "unlabeled_image_path = r'REFUGE2\\val\\images'\n",
    "\n",
    "unlabeled_train_dataset = UnsupervisedDataset(unlabeled_image_path, transform=unlabeled_transform)\n",
    "\n",
    "val_image_path = r'REFUGE2\\val\\images'\n",
    "val_mask_path = r'REFUGE2\\val\\mask'\n",
    "\n",
    "val_dataset = SupervisedDataset(val_image_path, val_mask_path,\n",
    "                            transform=labeled_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 320, 320]),\n",
       " torch.Size([320, 320]),\n",
       " torch.float32,\n",
       " torch.int64,\n",
       " tensor([0, 1, 2]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b = labeled_train_dataset[42]\n",
    "\n",
    "a.shape, b.shape, a.dtype, b.dtype, b.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, Iterable, List, Set, Tuple, TypeVar, Union, cast\n",
    "from functools import partial\n",
    "from torch import Tensor\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from operator import itemgetter, mul\n",
    "\n",
    "def uniq(a: Tensor) -> Set:\n",
    "    return set(torch.unique(a.cpu()).numpy())\n",
    "\n",
    "def sset(a: Tensor, sub) -> bool:\n",
    "    return uniq(a).issubset(sub)\n",
    "\n",
    "def simplex(t: Tensor, axis=1) -> bool:\n",
    "    _sum = cast(Tensor, t.sum(axis).type(torch.float32))\n",
    "    _ones = torch.ones_like(_sum, dtype=torch.float32)\n",
    "    return torch.allclose(_sum, _ones)\n",
    "\n",
    "def one_hot(t: Tensor, axis=1) -> bool:\n",
    "    return simplex(t, axis) and sset(t, [0, 1])\n",
    "\n",
    "def class2one_hot(seg: Tensor, K: int) -> Tensor:\n",
    "    # Breaking change but otherwise can't deal with both 2d and 3d\n",
    "    # if len(seg.shape) == 3:  # Only w, h, d, used by the dataloader\n",
    "    #     return class2one_hot(seg.unsqueeze(dim=0), K)[0]\n",
    "\n",
    "    assert sset(seg, list(range(K))), (uniq(seg), K)\n",
    "\n",
    "    b, *img_shape = seg.shape  # type: Tuple[int, ...]\n",
    "\n",
    "    device = seg.device\n",
    "    res = torch.zeros((b, K, *img_shape), dtype=torch.int32, device=device).scatter_(1, seg[:, None, ...], 1)\n",
    "\n",
    "    assert res.shape == (b, K, *img_shape)\n",
    "    assert one_hot(res)\n",
    "\n",
    "    return res\n",
    "\n",
    "def gt_transform(resolution: Tuple[float, ...], K: int):\n",
    "        return transforms.Compose([\n",
    "                lambda img: np.array(img.cpu())[...],\n",
    "                lambda nd: torch.tensor(nd, dtype=torch.int64)[None, ...],  # Add one dimension to simulate batch\n",
    "                partial(class2one_hot, K=K),\n",
    "                itemgetter(0)  # Then pop the element to go back to img shape\n",
    "        ])\n",
    "from scipy.ndimage import distance_transform_edt as eucl_distance\n",
    "\n",
    "def one_hot2dist(seg: np.ndarray, resolution: Tuple[float, float, float] = None,\n",
    "                 dtype=None) -> np.ndarray:\n",
    "    assert one_hot(torch.tensor(seg), axis=0)\n",
    "    K: int = len(seg)\n",
    "\n",
    "    res = np.zeros_like(seg, dtype=dtype)\n",
    "    for k in range(K):\n",
    "        posmask = seg[k].astype(bool)\n",
    "\n",
    "        if posmask.any():\n",
    "            negmask = ~posmask\n",
    "            res[k] = eucl_distance(negmask, sampling=resolution) * negmask \\\n",
    "                - (eucl_distance(posmask, sampling=resolution) - 1) * posmask\n",
    "        # The idea is to leave blank the negative classes\n",
    "        # since this is one-hot encoded, another class will supervise that pixel\n",
    "\n",
    "    return res\n",
    "\n",
    "def dist_map_transform(resolution: Tuple[float, ...], K: int):\n",
    "        return transforms.Compose([\n",
    "                gt_transform(resolution, K),\n",
    "                lambda t: t.cpu().numpy(),\n",
    "                partial(one_hot2dist, resolution=resolution),\n",
    "                lambda nd: torch.tensor(nd, dtype=torch.float32).to(device)\n",
    "        ])\n",
    "\n",
    "disttransform = dist_map_transform([1, 1], NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor, einsum\n",
    "\n",
    "class GeneralizedDiceLoss():\n",
    "    def __init__(self, **kwargs):\n",
    "        # Self.idc is used to filter out some classes of the target mask. Use fancy indexing\n",
    "        self.idc: List[int] = kwargs[\"idc\"]\n",
    "        print(f\"Initialized {self.__class__.__name__} with {kwargs}\")\n",
    "\n",
    "    def __call__(self, probs: Tensor, target: Tensor) -> Tensor:\n",
    "        assert simplex(probs) and simplex(target)\n",
    "\n",
    "        pc = probs[:, self.idc, ...].type(torch.float32)\n",
    "        tc = target[:, self.idc, ...].type(torch.float32)\n",
    "\n",
    "        w: Tensor = 1 / ((einsum(\"bkwh->bk\", tc).type(torch.float32) + 1e-10) ** 2)\n",
    "        intersection: Tensor = w * einsum(\"bkwh,bkwh->bk\", pc, tc)\n",
    "        union: Tensor = w * (einsum(\"bkwh->bk\", pc) + einsum(\"bkwh->bk\", tc))\n",
    "\n",
    "        divided: Tensor = 1 - 2 * (einsum(\"bk->b\", intersection) + 1e-10) / (einsum(\"bk->b\", union) + 1e-10)\n",
    "\n",
    "        loss = divided.mean()\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurfaceLoss():\n",
    "    def __init__(self, **kwargs):\n",
    "        # Self.idc is used to filter out some classes of the target mask. Use fancy indexing\n",
    "        self.idc: List[int] = kwargs[\"idc\"]\n",
    "        print(f\"Initialized {self.__class__.__name__} with {kwargs}\")\n",
    "\n",
    "    def __call__(self, probs: Tensor, dist_maps: Tensor) -> Tensor:\n",
    "        assert simplex(probs)\n",
    "        assert not one_hot(dist_maps)\n",
    "\n",
    "        pc = probs[:, self.idc, ...].type(torch.float32)\n",
    "        dc = dist_maps[:, self.idc, ...].type(torch.float32)\n",
    "\n",
    "        multipled = einsum(\"bkwh,bkwh->bkwh\", pc, dc)\n",
    "\n",
    "        loss = multipled.mean()\n",
    "\n",
    "        return loss\n",
    "\n",
    "BoundaryLoss = SurfaceLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(y_pred, labels, generalized_dice_loss_fn, boundary_loss_fn, alpha):\n",
    "    one_hot_labels = torch.stack([class2one_hot(label.unsqueeze(0), NUM_CLASSES).squeeze(0) for label in labels])\n",
    "    dist_map_labels = torch.stack([disttransform(label) for label in labels])\n",
    "    pred_probs = torch.softmax(y_pred, dim=1)\n",
    "\n",
    "    gdl_loss = generalized_dice_loss_fn(pred_probs, one_hot_labels)\n",
    "    bl_loss = boundary_loss_fn(pred_probs, dist_map_labels)\n",
    "\n",
    "    loss = gdl_loss + alpha*bl_loss\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(image, augmentation):\n",
    "    \"\"\"Apply augmentation to an image.\"\"\"\n",
    "    return augmentation(image=image)['image']\n",
    "\n",
    "def augment_batch(batch, augmentation):\n",
    "    \"\"\"Apply augmentation to a batch of images.\"\"\"\n",
    "    batch_np = batch.permute(0, 2, 3, 1).cpu().numpy()\n",
    "    augmented_images = [augment_image(image, augmentation).astype(np.float32) for image in batch_np]\n",
    "    return torch.tensor(np.stack(augmented_images)).permute(0, 3, 1, 2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unsupervised_train_step(unlabeled_images, model, generalized_dice_loss_fn, boundary_loss_fn, \n",
    "                            weak_aug, strong_aug, alpha, threshold):\n",
    "    u_w = augment_batch(unlabeled_images, weak_aug)\n",
    "    with torch.no_grad():\n",
    "        y_weak = model(u_w)\n",
    "    \n",
    "        y_weak = torch.softmax(y_weak, dim=1)\n",
    "\n",
    "    # get pixel-wise max probability\n",
    "    q_b = torch.max(y_weak, dim=1)[0]\n",
    "\n",
    "    # get image-wise mean of pixel-wise max probability\n",
    "    q_b_mean = torch.mean(q_b, dim=(1, 2))\n",
    "\n",
    "    mask = q_b_mean >= threshold\n",
    "\n",
    "    # return 0 loss if no image is above threshold\n",
    "    if mask.sum() == 0:\n",
    "        unsupervised_loss = torch.tensor(0).to(device)\n",
    "        return unsupervised_loss, mask.sum() / len(mask)\n",
    "\n",
    "    psudeo_labels = torch.argmax(y_weak, dim=1)[mask]\n",
    "    \n",
    "    u_s = augment_batch(unlabeled_images[mask], strong_aug)\n",
    "    y_strong = model(u_s)\n",
    "\n",
    "\n",
    "    unsupervised_loss = calculate_loss(y_strong, psudeo_labels, generalized_dice_loss_fn, boundary_loss_fn, alpha)\n",
    "\n",
    "    return unsupervised_loss, mask.sum() / len(mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervised_train_step(labeled_images, labeled_masks, model, generalized_dice_loss_fn, boundary_loss_fn, alpha):\n",
    "    y_pred = model(labeled_images)\n",
    "    supervised_loss = calculate_loss(y_pred, labeled_masks, generalized_dice_loss_fn, boundary_loss_fn, alpha)\n",
    "\n",
    "    return supervised_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(labeled_batch, unlabeled_batch, model, optimizer,\n",
    "                generalized_dice_loss_fn, boundary_loss_fn, weak_aug, strong_aug,\n",
    "                alpha, threshold, lambda_u, device ):\n",
    "    \n",
    "    labeled_images, labeled_masks = labeled_batch\n",
    "    unlabeled_images = unlabeled_batch\n",
    "\n",
    "    labeled_images = labeled_images.to(device)\n",
    "    labeled_masks = labeled_masks.to(device)\n",
    "    unlabeled_images = unlabeled_images.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    unsupervised_loss, mask_percent = unsupervised_train_step(unlabeled_images, model, generalized_dice_loss_fn, boundary_loss_fn, weak_aug, strong_aug, alpha, threshold)\n",
    "\n",
    "    supervised_loss = supervised_train_step(labeled_images, labeled_masks, model, generalized_dice_loss_fn, boundary_loss_fn, alpha)\n",
    "\n",
    "    total_loss = supervised_loss + lambda_u*unsupervised_loss\n",
    "    \n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return total_loss.item(), supervised_loss.item(), unsupervised_loss.item(), mask_percent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, generalized_dice_loss_fn, boundary_loss_fn, alpha, device):\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for images, masks in val_loader:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            y_pred = model(images)\n",
    "            loss = calculate_loss(y_pred, masks, generalized_dice_loss_fn, boundary_loss_fn, alpha)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_fixmatch(labeled_train_loader, unlabeled_train_loader, val_loader,\n",
    "                    model, optimizer, generalized_dice_loss_fn, boundary_loss_fn, \n",
    "                    weak_aug, strong_aug, alpha: float, threshold: float, lambda_u: float,\n",
    "                    device, max_epochs: int, early_stopping_patience: int, file_path: str):\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    early_stopping_counter = 0\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        L_sum = 0\n",
    "        L_u_sum = 0\n",
    "        L_s_sum = 0\n",
    "        mask_percent_sum = 0\n",
    "        count = 0\n",
    "\n",
    "        model.train()\n",
    "        for labeled_batch, unlabeled_batch in tqdm(zip(labeled_train_loader, unlabeled_train_loader), total=len(labeled_train_loader)):\n",
    "            L, L_s, L_u, mask_percent = train_step(labeled_batch, unlabeled_batch, model, optimizer,\n",
    "                        generalized_dice_loss_fn, boundary_loss_fn, \n",
    "                        weak_aug, strong_aug, alpha, threshold, lambda_u, device)\n",
    "            L_sum += L\n",
    "            L_s_sum += L_s\n",
    "            L_u_sum += L_u\n",
    "            mask_percent_sum += mask_percent\n",
    "            count += 1\n",
    "\n",
    "        print(f\"[Epoch {epoch+1}/{max_epochs}] | Loss: {L_sum/count:.6f} | L_s: {L_s_sum/count:.6f}, L_u: {L_u_sum/count:.6f} | Mask%: {100*mask_percent_sum/count:.2f}\")\n",
    "\n",
    "        val_loss = validate(val_loader, model, generalized_dice_loss_fn, boundary_loss_fn, alpha, device)\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            early_stopping_counter = 0\n",
    "\n",
    "            torch.save(model, file_path)\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "\n",
    "        if early_stopping_counter > early_stopping_patience:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nunlabeled_images = torch.randn(16, 3, 512, 512)\\nmodel = lambda a: torch.randn(a.shape[0], NUM_CLASSES, 512, 512)\\n\\ngeneralized_dice_loss_fn = GeneralizedDiceLoss(idc=list(range(NUM_CLASSES)))\\nboundary_loss_fn = BoundaryLoss(idc=list(range(1, NUM_CLASSES)))\\n\\nalpha = 0.05\\nthreshold = 0.2772\\n\\nweak_aug = get_weak_aug()\\nstrong_aug = get_strong_aug()\\n\\nunsupervised_loss = unsupervised_train_step(unlabeled_images, model, generalized_dice_loss_fn, boundary_loss_fn, \\n                            weak_aug, strong_aug, alpha, threshold)\\n\\nunsupervised_loss\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "unlabeled_images = torch.randn(16, 3, 512, 512)\n",
    "model = lambda a: torch.randn(a.shape[0], NUM_CLASSES, 512, 512)\n",
    "\n",
    "generalized_dice_loss_fn = GeneralizedDiceLoss(idc=list(range(NUM_CLASSES)))\n",
    "boundary_loss_fn = BoundaryLoss(idc=list(range(1, NUM_CLASSES)))\n",
    "\n",
    "alpha = 0.05\n",
    "threshold = 0.2772\n",
    "\n",
    "weak_aug = get_weak_aug()\n",
    "strong_aug = get_strong_aug()\n",
    "\n",
    "unsupervised_loss = unsupervised_train_step(unlabeled_images, model, generalized_dice_loss_fn, boundary_loss_fn, \n",
    "                            weak_aug, strong_aug, alpha, threshold)\n",
    "\n",
    "unsupervised_loss\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "model = smp.UnetPlusPlus(\n",
    "    encoder_name=\"efficientnet-b4\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    classes=NUM_CLASSES,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "\n",
    "def get_weak_aug():\n",
    "    \"\"\"Define weak augmentation pipeline.\"\"\"\n",
    "    return A.Compose([\n",
    "        A.Rotate(limit=20, p=1.0),\n",
    "        A.ElasticTransform(alpha=1, sigma=50, p=1.0)\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_strong_aug():\n",
    "    \"\"\"Define strong augmentation pipeline.\"\"\"\n",
    "    return A.Compose([\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "        A.Sharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=0.5),\n",
    "        A.GaussianBlur(blur_limit=(3, 7), p=1.0)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized GeneralizedDiceLoss with {'idc': [0, 1, 2]}\n",
      "Initialized SurfaceLoss with {'idc': [1, 2]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'model_2024-10-14_11-05-17.pt'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "mu = 1\n",
    "alpha = 1.0\n",
    "threshold = 0.90\n",
    "lambda_u = 1.0\n",
    "max_epochs = 100\n",
    "early_stopping_patience = 9\n",
    "now = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "file_path = f'model_{now}.pt'\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "labeled_train_loader = torch.utils.data.DataLoader(labeled_train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "unlabeled_train_loader = torch.utils.data.DataLoader(unlabeled_train_dataset, batch_size=BATCH_SIZE*mu, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "generalized_dice_loss_fn = GeneralizedDiceLoss(idc=list(range(NUM_CLASSES)))\n",
    "boundary_loss_fn = BoundaryLoss(idc=list(range(1, NUM_CLASSES)))\n",
    "\n",
    "weak_aug = get_weak_aug()\n",
    "strong_aug = get_strong_aug()\n",
    "\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â–         | 2/50 [00:17<06:56,  8.67s/it]"
     ]
    }
   ],
   "source": [
    "train_fixmatch(labeled_train_loader, unlabeled_train_loader, val_loader,\n",
    "                    model, optimizer, generalized_dice_loss_fn, boundary_loss_fn, \n",
    "                    weak_aug, strong_aug, alpha, threshold, lambda_u,\n",
    "                    device, max_epochs, early_stopping_patience, file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
